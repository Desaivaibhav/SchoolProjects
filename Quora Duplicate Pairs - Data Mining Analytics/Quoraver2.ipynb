{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hrishi\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Hrishi\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cs\n",
    "from sklearn.metrics.pairwise import manhattan_distances as md\n",
    "from sklearn.metrics.pairwise import euclidean_distances as ed\n",
    "from sklearn.metrics import jaccard_similarity_score as jsc\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time; \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import collections \n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Reading files\n",
    "train = pd.read_csv('D:/vaibhav/DataMining/Project/train.csv',encoding=\"utf-8\",nrows=50000)\n",
    "test = pd.read_csv('D:/vaibhav/DataMining/Project/test.csv',encoding=\"utf-8\",nrows=10000)\n",
    "\n",
    "\n",
    "#removing question pairs whose total word per question length is less than 10\n",
    "train['question1'] = train['question1'].astype('str')\n",
    "train['question2'] = train['question2'].astype('str')\n",
    "train = train[train['question2'].map(len)>9]\n",
    "train = train[train['question1'].map(len)>9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hrishi\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of words in the dictionary = 19041\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_train, df_test = train_test_split(train, test_size = 0.02)\n",
    "\n",
    "words = re.compile(r\"\\w+\",re.I)\n",
    "stopword = ['a','an','the','is']\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize_questions(df):\n",
    "    #question_1_tokenized = []\n",
    "    #question_2_tokenized = []\n",
    "    \n",
    "    for i in (1, 2):\n",
    "        df['Question_%s_tok' % i] = df['question%s' % i].apply(nltk.word_tokenize)\n",
    "\n",
    "    return df\n",
    "\n",
    "def train_dictionary(df):\n",
    "    \n",
    "    questions_tokenized = df.Question_1_tok.tolist() + df.Question_2_tok.tolist()\n",
    "    \n",
    "    dictionary = corpora.Dictionary(questions_tokenized)\n",
    "    dictionary.filter_extremes(no_below=5, no_above=0.8)\n",
    "    dictionary.compactify()\n",
    "    \n",
    "    return dictionary\n",
    "    \n",
    "df_train = tokenize_questions(df_train)\n",
    "dictionary = train_dictionary(df_train)\n",
    "print (\"No of words in the dictionary = %s\" %len(dictionary.token2id))\n",
    "\n",
    "df_test = tokenize_questions(df_test)\n",
    "test=tokenize_questions(test)\n",
    "\n",
    "\n",
    "\n",
    "def get_vectors(df, dictionary):\n",
    "    \n",
    "    question1_vec = [dictionary.doc2bow(text) for text in df.Question_1_tok.tolist()]\n",
    "    question2_vec = [dictionary.doc2bow(text) for text in df.Question_2_tok.tolist()]\n",
    "    \n",
    "    question1_csc = gensim.matutils.corpus2csc(question1_vec, num_terms=len(dictionary.token2id))\n",
    "    question2_csc = gensim.matutils.corpus2csc(question2_vec, num_terms=len(dictionary.token2id))\n",
    "    \n",
    "    return question1_csc.transpose(),question2_csc.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95728, 19041)\n",
      "(95728, 19041)\n"
     ]
    }
   ],
   "source": [
    "q1_csc, q2_csc = get_vectors(df_train, dictionary)\n",
    "\n",
    "print (q1_csc.shape)\n",
    "print (q2_csc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine_sim sample= \n",
      " [0.10101525445522107, 0.52704627669472992]\n",
      "eucledian_dis sample = \n",
      " [4.358898943540674, 6.0827625302982193]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mms_scale_euc = MinMaxScaler()\n",
    "\n",
    "def get_similarity_values(q1_csc, q2_csc):\n",
    "    cosine_sim = []\n",
    "    eucledian_dis = []\n",
    "    \n",
    "    for i,j in zip(q1_csc, q2_csc):\n",
    "        sim = cs(i,j)\n",
    "        cosine_sim.append(sim[0][0])\n",
    "        sim = ed(i,j)\n",
    "        eucledian_dis.append(sim[0][0])\n",
    "    \n",
    "    return cosine_sim, eucledian_dis  \n",
    "\n",
    "\n",
    "# cosine_sim = get_cosine_similarity(q1_csc, q2_csc)\n",
    "cosine_sim, eucledian_dis = get_similarity_values(q1_csc, q2_csc)\n",
    "print (\"cosine_sim sample= \\n\", cosine_sim[0:2])\n",
    "print (\"eucledian_dis sample = \\n\", eucledian_dis[0:2])\n",
    "\n",
    "eucledian_dis_array = np.array(eucledian_dis).reshape(-1,1)\n",
    "    \n",
    "eucledian_dis_array = mms_scale_euc.fit_transform(eucledian_dis_array)\n",
    "\n",
    "eucledian_dis = eucledian_dis_array.flatten()\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def calculate_logloss(y_true, y_pred):\n",
    "    loss_cal = log_loss(y_true, y_pred)\n",
    "    return loss_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated log loss value on the test set for cosine sim is = 1.026627\n",
      "The calculated log loss value on the test set for euclidean sim is = 0.632009\n"
     ]
    }
   ],
   "source": [
    "q1_csc_test, q2_csc_test = get_vectors(df_test, dictionary)\n",
    "y_pred_cos,  y_pred_euc = get_similarity_values(q1_csc_test, q2_csc_test)\n",
    "y_true = df_test.is_duplicate.tolist()\n",
    "\n",
    "y_pred_euc_array = mms_scale_euc.transform(np.array(y_pred_euc).reshape(-1,1))\n",
    "y_pred_euc = y_pred_euc_array.flatten()\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_cos)\n",
    "print (\"The calculated log loss value on the test set for cosine sim is = %f\" %logloss)\n",
    "\n",
    "logloss = calculate_logloss(y_true, y_pred_euc)\n",
    "print (\"The calculated log loss value on the test set for euclidean sim is = %f\" %logloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The calculated log loss value on the test set using logistic is = 7.176437\n",
      "The calculated log loss value on the test set using CART is = 6.769890\n",
      "The calculated log loss value on the test set using RFR is = 6.840595\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X_train = pd.DataFrame({\"cos\" : cosine_sim, \"euc\" : eucledian_dis})\n",
    "y_train = df_train.is_duplicate\n",
    "\n",
    "X_test = pd.DataFrame({\"cos\" : y_pred_cos,  \"euc\" : y_pred_euc})\n",
    "y_test = y_true\n",
    "\n",
    "#xtest=pd.DataFrame({\"cos\" : y_pred_costst,  \"euc\" : y_pred_euctst})\n",
    "\n",
    "cart=DecisionTreeClassifier()\n",
    "cart.fit(X_train, y_train)\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "rfr = RandomForestClassifier()\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train,y_train)\n",
    "\n",
    "y_cart_predicted = cart.predict(X_test)\n",
    "y_log_predicted = logreg.predict(X_test)\n",
    "y_rfr_predicted = rfr.predict(X_test)\n",
    "y_svr_predicted = svr.predict(X_test)\n",
    "\n",
    "#y_svr_predictedtst=svr.predict(xtest)\n",
    "\n",
    "logloss_logreg = calculate_logloss(y_test, y_log_predicted)\n",
    "logloss_cart = calculate_logloss(y_test, y_cart_predicted)\n",
    "logloss_rfr = calculate_logloss(y_test, y_rfr_predicted)\n",
    "logloss_svr = calculate_logloss(y_test, y_svr_predicted)\n",
    "\n",
    "#sub = pd.DataFrame()\n",
    "#sub['test_id'] = test['id']\n",
    "#sub['is_duplicate'] = y_svr_predictedtst\n",
    "print (\"The calculated log loss value on the test set using logistic is = %f\" %logloss_logreg)\n",
    "print (\"The calculated log loss value on the test set using CART is = %f\" %logloss_cart)\n",
    "print (\"The calculated log loss value on the test set using RFR is = %f\" %logloss_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.803986 (0.002032)\n",
      "RFR: 0.810484 (0.001740)\n",
      "CART: 0.813451 (0.002067)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEVCAYAAAD+TqKGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRESlBEVERFRKUERERKUERUREVPr/BIbklpjWj/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b54d4a45c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# prepare configuration for cross validation test harness\n",
    "seed = 7\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('RFR', RandomForestClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\tcv_results = model_selection.cross_val_score(model, X_train,y_train, cv=kfold, scoring=scoring)\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "\tprint(msg)\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
